---
title: "First Pass Results "
author: "Andie Creel"
date: "2022-12-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# -----------------------------------------------------------------------------
# loading packages 
# -----------------------------------------------------------------------------
rm(list = ls())
library(vroom)
library(dplyr)
library(ggplot2)
library(tidyr)
library(stringr)
library(fixest)
library(kableExtra)
source('3.functions.R')
library(vroom)
```

# Initial Data Exploration 

This uses the summary data, not the daily diary data.

This is NOT conditioned on people who recreate. 

```{r, echo = FALSE, message=FALSE}
# -----------------------------------------------------------------------------
# reading in data
# -----------------------------------------------------------------------------
myList <- list()

for (k in 3:21){

  myFile <- paste0("clean_data/ATUS_2003-2021/", 2000 + k, ".csv")
  myList[[k]] <- vroom(myFile)
  
}

# -----------------------------------------------------------------------------
# function
# -----------------------------------------------------------------------------

# Where I got the calculation for average take spent recreating per day
# In zotero: “American Time Use Survey User’s Guide,” 2022, 125.
# uses the weights

get_avg_rec_min <- function(df){
  sum(df$sample_weight*df$total_min_rec)/sum(df$sample_weight)
}

# -----------------------------------------------------------------------------
# make data frame with averages
# -----------------------------------------------------------------------------

myYear <- 2003:2021
myAverages <- data.frame(year = myYear, avg_min_per_day = NA)

# -----------------------------------------------------------------------------
# break down by race
# -----------------------------------------------------------------------------

for (y in 3:21) {
  myAverages$avg_min_per_day[y-2] <- get_avg_rec_min(myList[[y]])
  
  # break down by race
  # 1 White only
  # 2 Black only
  # 3 American Indian, Alaskan Native only
  # 4 Asian only
  # 5 Hawaiian/Pacific Islander only 
  # https://www.bls.gov/tus/atuscpscodebk14.pdf
  
  myRaceList <- list()
  for (r in 1:5) {
    myRaceList[[r]] <- myList[[y]] %>%
      select(household_id, race, week_earning, sample_weight, total_min_rec) %>% 
      filter(race == r)
    
    if (r == 1){
      myAverages$avg_min_per_day_white[y-2] <- get_avg_rec_min(myRaceList[[r]])
      
    } else if (r == 2){
      myAverages$avg_min_per_day_black[y-2] <- get_avg_rec_min(myRaceList[[r]])
      
    } else if (r == 3){
      myAverages$avg_min_per_day_native[y-2] <- get_avg_rec_min(myRaceList[[r]])
    } else if (r == 4){
      myAverages$avg_min_per_day_asian[y-2] <- get_avg_rec_min(myRaceList[[r]])
    } else if (r == 5){
      myAverages$avg_min_per_day_island[y-2] <- get_avg_rec_min(myRaceList[[r]])
    }
  }
}

# -----------------------------------------------------------------------------
# plots
# -----------------------------------------------------------------------------

# Country Averages  -------------------

myAverages %>%
  ggplot(aes(x = year, y = avg_min_per_day)) +
  geom_point(colour = "black", size = 3) +
  geom_smooth(aes(y = avg_min_per_day), method = "lm", fill = "grey", color = "darkred", size = 1.5) +
  ggtitle("Time recreating may be increasing", "Recreation increased ~7% from 2003-2021") +
  ylab("Minutes") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, 2003-2021")+
  theme_bw() + 
  scale_colour_manual("", 
                      breaks = c("Population", "White", "Black"),
                      values = c("darkred", "darkblue", "darkgreen")) +
  theme(text = element_text(size=17))
 
ggsave(width = 11, height = 8, filename = "figures/country-average.jpeg")
```

This increasing trend may actually be driven by the COVID bump in 2020, and there is allegedly little trust that the 2020 weights for the ATUS survey are correct that year.


```{r, echo=FALSE, message=FALSE}
# Race -------------------

#pivot long
myAverages_thin <- myAverages %>%
  select(year, avg_min_per_day, avg_min_per_day_black, avg_min_per_day_white)

myAverages_long <- myAverages %>%
  select(year, avg_min_per_day, avg_min_per_day_black, avg_min_per_day_white) %>%
  rename(All = avg_min_per_day) %>%
  rename(Black = avg_min_per_day_black) %>%
  rename(White = avg_min_per_day_white) %>%
  pivot_longer(cols = c(All, White, Black), values_to = "avg_min") %>%
  select(year, name, avg_min) %>%
  rename(Race = name)

ggplot(myAverages_long, aes(x = year, y = avg_min, colour = Race)) +
  geom_smooth(method = "lm", fill = "Grey", size = 1.5) +
  ggtitle("Time recreating varries by race") +
  ylab("Minutes") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, 2003-2021")+
  theme_bw() + 
  theme(text = element_text(size=17))

ggsave(width = 11, height = 8, filename = "figures/country-average-race.jpeg")

```

The Black Americans spend ~20% less time recreating daily than the average American.


# Data 

Use ATUS, CPS and respondent file to build dataset of daily diary information. Do a significant amount of data manipulation to get file workable for original regression equation. 

```{r data, include=FALSE, message=FALSE}



# -----------------------------------------------------------------------------
# reading in data
# this should be make into a function where I can do it for each year, later
# -----------------------------------------------------------------------------

#read in activity file (daily diary)
myAct_21_og <-vroom("raw_data/atusact-2021/atusact_2021.dat")

# read in respondent file (has the weights)
myResp_21_og <- vroom("raw_data/atusresp-2021/atusresp_2021.dat")

# read in cps file (has state, fips info)
myCPS_21_og <- vroom("raw_data/atuscps-2021/atuscps_2021.dat")

# -----------------------------------------------------------------------------
# data cleaning and construction 
# -----------------------------------------------------------------------------

#activity file (activities and duration)
myAct <- clean_activity(myAct_21_og) %>%
  get_duration()

#cps (race, income, fips)
myCPS <- clean_cps(myCPS_21_og) %>% # clean to relevant variables
  get_income() # transform income from categories to numbers (low, mid, and upper estimates)

#respondents (weights)
myResp <- clean_resp(myResp_21_og)


# merge
myWorking <- left_join(myAct, myCPS, by = "id") %>%
  left_join(myResp, by = "id")

```



# Initial Regression (2021)

Specification one: 
$$\log(Min\_Rec_i) = \alpha  + \beta Min\_Travel_i + \gamma Income_i$$
where $\alpha$ is the intercept for the entire country.


Specification two: 
$$\log(Min\_Rec_i) =  \beta Min\_Travel_i + \gamma Income_i + \alpha_{state}$$
where $\alpha_{st}$ is a state fixed effect. 


In both specifications, minutes recreating is total number of minutes recreating by an individual on the day they were survey. Minutes travel are total number of minutes travel for recreation by an individual on the day there were surveryed. 

Income is reported categorically. I do low, midpoint, and upper income approximations for individuals. 

```{r, message=FALSE, echo=FALSE}

# -----------------------------------------------------------------------------
# Initial regression 
# -----------------------------------------------------------------------------

# need to log LHS
myWorking$log_duration_rec <- log(myWorking$duration_rec)


reg_1 <- feols(fml = log_duration_rec ~ duration_travel + family_income_mid, 
               data = myWorking)
reg_2 <- feols(fml = log_duration_rec ~ duration_travel + family_income_mid | fips_st,
               data = myWorking)
reg_3 <- feols(fml = log_duration_rec ~ duration_travel + family_income_low | fips_st,
               data = myWorking)
reg_4 <- feols(fml = log_duration_rec ~ duration_travel + family_income_up | fips_st,
               data = myWorking)


etable(reg_1,
       reg_2,
       reg_3,
       reg_4,
       signif.code = c("***"=0.01, "**"=0.05, "*"=0.10)) %>%
  kbl(booktabs = T, caption = "Race") %>%
  kable_styling(latex_options = c("scale_down","HOLD_position")) 


```

duration on travel increase duration recreating 

This is not the model necessary to estimate a demand curve needed for welfare estimates. This is not a travel cost model because I do not have quantity in my data set. 

NEXT STEPS 

- demographic characteristics of people who travel for recreation (have code 1813) and those who report recreating somewhere other than home (13XX filter) but don't report traveling
- figure out what to do with the minutes recreating on travel time.. fundamentally not a travel cost model. 
- Lower bound 

# Lower Bound on Value of Recreation 

```{r}

# first doing it with 2021 

# -----------------------------------------------------------------------------
# Read in data and clean
# -----------------------------------------------------------------------------

#from data clean (these are the summary files, not the daily diary)
my2021_og <- vroom("clean_data/ATUS_2003-2021/2021.csv") 

# one third hourly wage rate for OC per hour. I calc per minute. 
my2021 <- my2021_og %>%
  select(household_id, race, week_earning, sample_weight, total_min_rec, total_min_travel) %>%
  mutate(week_earning = ifelse(week_earning < 0 , NA, week_earning)) %>%
  mutate(OC_time_per_hour = round(week_earning / 40 * (1/3), 2)) %>% # opportunity cost of time
  mutate(OC_time_per_min = round(OC_time_per_hour/60, 4)) %>%
  mutate(travel_cost_lower_bound_NOTweighted = OC_time_per_min*total_min_travel) %>%
  mutate(travel_cost_lower_bound_weighted = travel_cost_lower_bound_NOTweighted*sample_weight)

#48% of people don't report their income :( 
round(sum(is.na(my2021$week_earning))/length(my2021$week_earning), 2) 

#sum of oc_travel lower bound
sum(my2021$travel_cost_lower_bound_weighted, na.rm = TRUE) #20 million 


```
Next steps 
- estimate mean and variance of travel_cost_lower_bound_NOTweighted 
    - estimate for white, black, etc. etc. 
- multiply by population to get the lower bound esimate 







