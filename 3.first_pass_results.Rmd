---
title: "First Pass Results "
author: "Andie Creel"
date: "2022-12-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# -----------------------------------------------------------------------------
# loading packages 
# -----------------------------------------------------------------------------
rm(list = ls())
library(vroom)
library(dplyr)
library(ggplot2)
library(tidyr)
library(stringr)
library(fixest)
library(kableExtra)
source('3.functions.R')
library(vroom)
library(stargazer)
```

# Initial Data Exploration 

This uses the summary data, not the daily diary data.

This is NOT conditioned on people who recreate. 

```{r, echo = FALSE, message=FALSE}
# -----------------------------------------------------------------------------
# reading in data
# -----------------------------------------------------------------------------
mySummary_files <- list()

for (k in 3:21){

  myFile <- paste0("clean_data/ATUS_2003-2021/", 2000 + k, ".csv")
  mySummary_files[[k]] <- vroom(myFile) %>%
    mutate(year = 2000+k) # add in year
  
  #adjust for inflation, in 2021 dollars
  myInf <- vroom("clean_data/inflation_rates.csv")
  
  mySummary_files[[k]] <- left_join(mySummary_files[[k]], myInf, by = "year") %>%
    mutate(week_earning_nominal = week_earning) %>%
    mutate(week_earning = week_earning_nominal/adj_value)
}


# -----------------------------------------------------------------------------
# make data frame with averages
# -----------------------------------------------------------------------------

myYear <- 2003:2021
myMinutes <- data.frame(year = myYear, avg_min_per_day = NA)

# -----------------------------------------------------------------------------
# break down by race
# -----------------------------------------------------------------------------

for (y in 3:21) {
  myMinutes$avg_min_per_day[y-2] <- get_avg_rec_min(mySummary_files[[y]])
  
  # break down by race
  # 1 White only
  # 2 Black only
  # 3 American Indian, Alaskan Native only
  # 4 Asian only
  # 5 Hawaiian/Pacific Islander only 
  # https://www.bls.gov/tus/atuscpscodebk14.pdf
  
  myRaceList <- list()
  for (r in 1:5) {
    myRaceList[[r]] <- mySummary_files[[y]] %>%
      select(household_id, race, week_earning, sample_weight, total_min_rec) %>% 
      filter(race == r)
    
    if (r == 1){
      myMinutes$avg_min_per_day_white[y-2] <- get_avg_rec_min(myRaceList[[r]])
      
    } else if (r == 2){
      myMinutes$avg_min_per_day_black[y-2] <- get_avg_rec_min(myRaceList[[r]])
      
    } else if (r == 3){
      myMinutes$avg_min_per_day_native[y-2] <- get_avg_rec_min(myRaceList[[r]])
    } else if (r == 4){
      myMinutes$avg_min_per_day_asian[y-2] <- get_avg_rec_min(myRaceList[[r]])
    } else if (r == 5){
      myMinutes$avg_min_per_day_island[y-2] <- get_avg_rec_min(myRaceList[[r]])
    }
  }
}

# -----------------------------------------------------------------------------
# plots
# -----------------------------------------------------------------------------

# Country Averages  -------------------

myMinutes %>%
  ggplot(aes(x = year, y = avg_min_per_day)) +
  geom_point(colour = "black", size = 3, alpha = .5) +
  geom_smooth(aes(y = avg_min_per_day), method = "lm", fill = 'grey', color = "black", size = 1.5) +
  ggtitle("Americans recreate outside for 18-19 min per day") +
  ylab("Minutes") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() + 
  theme(text = element_text(size=17))
  # coord_cartesian(ylim = c(0, 30))  #zoom

 
ggsave(width = 11, height = 8, filename = "figures/minutes.jpeg")
```

This increasing trend may actually be driven by the COVID bump in 2020, and there is allegedly little trust that the 2020 weights for the ATUS survey are correct that year.


```{r, results = 'asis', echo=FALSE, message=FALSE}
# -----------------------------------------------------------------------------
# plots
# -----------------------------------------------------------------------------
#pivot long to make graphs
myMinutes_long <- myMinutes %>%
  rename(Nation = avg_min_per_day) %>%
  rename(Black = avg_min_per_day_black) %>%
  rename(White = avg_min_per_day_white) %>%
  rename(Native = avg_min_per_day_native) %>%
  rename(Asian = avg_min_per_day_asian) %>%
  rename(Islander = avg_min_per_day_island) %>%
  pivot_longer(cols = c(Nation, White, Black,Native, Islander, Asian), values_to = "avg_min") %>%
  select(year, name, avg_min) %>%
  rename(Race = name)

ggplot(myMinutes_long, aes(x = year, y = avg_min, colour = Race)) +
  geom_smooth(method = "lm", fill = NA, size = 1.5) +
  geom_point(size = 2, alpha = .25) +
  ggtitle("Time recreating varries by race", "FILL") +
  ylab("Minutes") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() + 
  theme(text = element_text(size=17)) +
  # coord_cartesian(ylim = c(0, 30))+  #zoom
    scale_color_manual(values=c('darkcyan', 'darkgoldenrod4', 'darkmagenta',  'black', 'darkolivegreen4','darkred'))


ggsave(width = 11, height = 8, filename = "figures/minutes-race.jpeg")


# -----------------------------------------------------------------------------
# seperating out to show error 
# -----------------------------------------------------------------------------

#native and Islander
myMinutes_long %>%
  filter(Race == 'Islander' | Race == 'Nation' | Race == "Native" ) %>%
  ggplot(aes(x = year, y = avg_min, colour = Race)) +
  geom_smooth(method = "lm", fill = 'grey', size = 1.5) +
  geom_point(size = 2, alpha = .25) +
  ggtitle("Figure 3: Islander and Native Americans' Estimates are Variant") +
  ylab("Minutes") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() + 
  theme(text = element_text(size=17)) +
  # coord_cartesian(ylim = c(0, 30))+  #zoom
    scale_color_manual(values=c('darkmagenta',  'black', 'darkolivegreen4'))
ggsave(width = 11, height = 8, filename = "figures/minutes-islander-native.jpeg")


#White, asian, black
myMinutes_long %>%
  filter(Race == "Nation" | Race == 'White' | Race == 'Asian' | Race == 'Black') %>%
  ggplot(aes(x = year, y = avg_min, colour = Race)) +
  geom_smooth(method = "lm", fill = 'grey', size = 1.5) +
  geom_point(size = 2, alpha = .25) +
  ggtitle("Figure 2: Black Americans Recreate Less than White and Asian") +
  ylab("Minutes") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() + 
  theme(text = element_text(size=17)) +
  # coord_cartesian(ylim = c(0, 30))+  #zoom
    scale_color_manual(values=c('darkcyan', 'darkgoldenrod4', 'black', 'darkred'))
ggsave(width = 11, height = 8, filename = "figures/minutes-white-black-asian.jpeg")


# -----------------------------------------------------------------------------
# Tables
# -----------------------------------------------------------------------------

one<- lm(formula  = avg_min ~ year, data = myMinutes_long %>%filter(Race == 'Nation'))
two<- lm(formula= avg_min ~ year, data = myMinutes_long %>%filter(Race == 'White'))
three<- lm(formula = avg_min ~ year, data = myMinutes_long %>%filter(Race == 'Black'))
four<- lm(formula = avg_min ~ year, data = myMinutes_long %>%filter(Race == 'Asian'))
five<- lm(formula = avg_min ~ year, data = myMinutes_long %>%filter(Race == 'Native'))
six<- lm(formula = avg_min ~ year, data = myMinutes_long %>%filter(Race == 'Islander'))

stargazer(one, two, three, four, five, six,
          column.labels = c("Nation", "White", "Black", "Asian", "Native", "Islander"),
          dep.var.caption = "Average Minutes Recreated Per Day",
          dep.var.labels.include = FALSE,
          out = 'test.htm')


```

The Black Americans spend ~20% less time recreating daily than the average American.


# Data 

Use ATUS, CPS and respondent file to build dataset of daily diary information. Do a significant amount of data manipulation to get file workable for original regression equation. 

```{r data, include=FALSE, message=FALSE}



# -----------------------------------------------------------------------------
# reading in data
# this should be make into a function where I can do it for each year, later
# -----------------------------------------------------------------------------

#read in activity file (daily diary)
myAct_21_og <-vroom("raw_data/atusact-2021/atusact_2021.dat")

# read in respondent file (has the weights)
myResp_21_og <- vroom("raw_data/atusresp-2021/atusresp_2021.dat")

# read in cps file (has state, fips info)
myCPS_21_og <- vroom("raw_data/atuscps-2021/atuscps_2021.dat")

# -----------------------------------------------------------------------------
# data cleaning and construction 
# -----------------------------------------------------------------------------

#activity file (activities and duration)
myAct <- clean_activity(myAct_21_og) %>%
  get_duration()

#cps (race, income, fips)
myCPS <- clean_cps(myCPS_21_og) %>% # clean to relevant variables
  get_income() # transform income from categories to numbers (low, mid, and upper estimates)

#respondents (weights)
myResp <- clean_resp(myResp_21_og)


# merge
myWorking <- left_join(myAct, myCPS, by = "id") %>%
  left_join(myResp, by = "id")

```



# Initial Regression (2021)

Specification one: 
$$\log(Min\_Rec_i) = \alpha  + \beta Min\_Travel_i + \gamma Income_i$$
where $\alpha$ is the intercept for the entire country.


Specification two: 
$$\log(Min\_Rec_i) =  \beta Min\_Travel_i + \gamma Income_i + \alpha_{state}$$
where $\alpha_{st}$ is a state fixed effect. 


In both specifications, minutes recreating is total number of minutes recreating by an individual on the day they were survey. Minutes travel are total number of minutes travel for recreation by an individual on the day there were surveryed. 

Income is reported categorically. I do low, midpoint, and upper income approximations for individuals. 

```{r, message=FALSE, echo=FALSE}

# -----------------------------------------------------------------------------
# Initial regression 
# -----------------------------------------------------------------------------

# need to log LHS
myWorking$log_duration_rec <- log(myWorking$duration_rec)


reg_1 <- feols(fml = log_duration_rec ~ duration_travel + family_income_mid, 
               data = myWorking)
reg_2 <- feols(fml = log_duration_rec ~ duration_travel + family_income_mid | fips_st,
               data = myWorking)
reg_3 <- feols(fml = log_duration_rec ~ duration_travel + family_income_low | fips_st,
               data = myWorking)
reg_4 <- feols(fml = log_duration_rec ~ duration_travel + family_income_up | fips_st,
               data = myWorking)


etable(reg_1,
       reg_2,
       reg_3,
       reg_4,
       signif.code = c("***"=0.01, "**"=0.05, "*"=0.10)) %>%
  kbl(booktabs = T, caption = "Race") %>%
  kable_styling(latex_options = c("scale_down","HOLD_position")) 

rm(reg_1, reg_2, reg_3, reg_4)


```

duration on travel increase duration recreating 

This is not the model necessary to estimate a demand curve needed for welfare estimates. This is not a travel cost model because I do not have quantity in my data set. 

NEXT STEPS 

- demographic characteristics of people who travel for recreation (have code 1813) and those who report recreating somewhere other than home (13XX filter) but don't report traveling

# Lower Bound on Value of Recreation 


```{r, echo = FALSE, message=FALSE}

# -----------------------------------------------------------------------------
# get average travel cost and SE for whole country and each race
# -----------------------------------------------------------------------------
# Have already read all summary file into mySummary_files (already inflation adjusted)
# Functions are in files 


# -----------------------------------------------------------------------------
# get average travel cost per day per person and SE for each year
# -----------------------------------------------------------------------------

myTC_files <- list()
myTC <- data.frame(year = numeric(),
                            avg_travel_cost_0 = numeric(),
                            variance = numeric(),
                            standard_error = numeric())

for (y in 5:21) {

  #travel cost cleaning 
 myTC_files[[y]] <- mySummary_files[[y]]  %>%
    select(household_id, race, week_earning, sample_weight, total_min_rec, total_min_travel) %>%
  
    #don't have weekly earnings for like 50% of people
    mutate(week_earning = ifelse(week_earning < 0 , NA, week_earning)) %>% 
    filter(!is.na(week_earning)) %>% 
   
   # opportunity cost of time
    mutate(OC_time_per_hour = round(week_earning / 40 * (1/3), 2)) %>% 
    mutate(OC_time_per_min = round(OC_time_per_hour/60, 4)) %>%
   
   #travel cost incurred per min reported traveling for recreation (numerator of mean)
    mutate(indv_travel_cost = OC_time_per_min*total_min_travel) %>%
    
    # average travel cost !
    mutate(avg_travel_cost_0 = sum(indv_travel_cost*sample_weight)/sum(sample_weight)) #y^hat_0
 
 #get standard errors 
 myTC <- bind_rows(myTC, get_SE(myTC_files[[y]], y))
 
 
}

# -----------------------------------------------------------------------------
# back of envelope calculations 
# -----------------------------------------------------------------------------

# need to get population, do variance transformation 
myPop <- vroom("clean_data/USA_pop.csv") %>%
  select(year, population)

myTC <- left_join(myTC, myPop, by = "year") %>%
  mutate(annual_TC_value = avg_travel_cost_0*population*365) %>%
  mutate(annual_TC_variance = (avg_travel_cost_0*population)^2*variance) %>%
  mutate(annual_TC_SE = sqrt(annual_TC_variance)) %>%
  mutate(annual_TC_CI = 1.96*annual_TC_SE) %>%
  mutate(race = "Nation")



# -----------------------------------------------------------------------------
# Graph
# -----------------------------------------------------------------------------

myTC_graph <- myTC %>%
  select(year, annual_TC_value, annual_TC_SE, race) %>%
  mutate(annual_TC_value_bill = annual_TC_value/1000000000) %>%
  mutate(annual_TC_SE_bill = annual_TC_SE/1000000000)
  

myTC_graph %>%
  ggplot(aes(x = year, y = annual_TC_value_bill)) +
  geom_point(colour = "black", size = 3, alpha = .5) +
  geom_smooth(aes(y = annual_TC_value_bill), method = "lm", fill = "grey", color = "black", size = 1.5) +
  ggtitle("Annual Value of Outdoor Recreation", subtitle = "A lower bound estimate using travel cost method") +
  ylab("Billions of 2021 USD ") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() +
  theme(text = element_text(size=17))

ggsave(width = 11, height = 8, filename = "figures/value.jpeg")


```


## Race
I break it down by calculating that average value of outdoor recreation every day (using the travel cost method) and then calculate the counter factual for if everyone in the country experienced the same average benefit of parks as various racial group. 

In these back of the envelope calcs, I'm always using the same annual population, but use the different average benefits associated with different racial groups. 


```{r, echo=FALSE, message=FALSE}

# -----------------------------------------------------------------------------
# break down by race
# -----------------------------------------------------------------------------

# build a myTC dataset for each race
myTC_race <- data.frame(year = numeric(),
                            avg_travel_cost_0 = numeric(),
                            variance = numeric(),
                            standard_error = numeric(), 
                            race = numeric())

myTC_temp <- myTC_race

#loop through races
for (r in 1:5) {
  
  # loop through years
  for (y in 5:21) {
    
    #travel cost files already exist from above
    myDF_temp <- myTC_files[[y]] %>%
      filter(race == r) %>%
      #RECALCULATE AVG TC 
      mutate(avg_travel_cost_0 = sum(indv_travel_cost*sample_weight)/sum(sample_weight))
      
    mySE_temp <- get_SE(myDF_temp, y) %>%
       mutate(race = r)
    
    #get standard errors 
     myTC_temp <- bind_rows(myTC_temp, mySE_temp) 
  }
  
  myTC_race <- bind_rows(myTC_temp)

}

# -----------------------------------------------------------------------------
# back of envelope calculations 
# -----------------------------------------------------------------------------

#using US population in all calculations (kinda a counter factual)

myTC_race <- left_join(myTC_race, myPop, by = "year") %>%
  mutate(annual_TC_value = avg_travel_cost_0*population*365) %>%
  mutate(annual_TC_variance = (avg_travel_cost_0*population)^2*variance) %>%
  mutate(annual_TC_SE = sqrt(annual_TC_variance)) %>%
  mutate(annual_TC_CI = 1.96*annual_TC_SE) %>%
  mutate(race = as.factor(race)) %>%
  mutate(race = ifelse(race == 1, "White", race)) %>%
  mutate(race = ifelse(race == 2, "Black", race)) %>%
  mutate(race = ifelse(race == 3, "Native", race)) %>%
  mutate(race = ifelse(race == 4, "Asian", race)) %>%
  mutate(race = ifelse(race == 5, "Islander", race))


# -----------------------------------------------------------------------------
# Graph 
# -----------------------------------------------------------------------------

myTC_race_graph <- myTC_race %>%
  select(year, race, annual_TC_value, annual_TC_SE) %>%
  mutate(annual_TC_value_bill = annual_TC_value/1000000000) %>%
  mutate(annual_TC_SE_bill = annual_TC_SE/1000000000) %>%
  bind_rows(myTC_graph)

  # break down by race
  # 1 White only
  # 2 Black only
  # 3 American Indian, Alaskan Native only
  # 4 Asian only
  # 5 Hawaiian/Pacific Islander only 
  # https://www.bls.gov/tus/atuscpscodebk14.pdf
  
myTC_race_graph %>%
  ggplot(aes(x = year, y = annual_TC_value_bill, colour = race)) +
  geom_point(size = 2, alpha = .25) +
  geom_smooth(method = "lm", fill = NA, size = 1.5) +
  ggtitle("Value using daily benefit of different races", "Counter factual analysis") +
  ylab(" Billions (2021 $) ") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() +
  theme(text = element_text(size=17)) +
  coord_cartesian(ylim = c(0, 80))+  #zoom
    scale_color_manual(values=c('darkcyan', 'darkgoldenrod4', 'darkmagenta',  'black', 'darkolivegreen4','darkred'))

ggsave(width = 11, height = 8, filename = "figures/value-race.jpeg")


# -----------------------------------------------------------------------------
# broken down with CI 
# -----------------------------------------------------------------------------
#native and Islander
myTC_race_graph %>%
  filter(race == 'Islander' | race == 'Nation' | race == "Native" ) %>%
  ggplot(aes(x = year, y = annual_TC_value_bill, colour = race)) +
  geom_point(size = 2, alpha = .25) +
  geom_smooth(method = "lm", fill = 'grey', size = 1.5) +
  ggtitle("Figure 5: Value estimates are variant for Islander and Native Americans", "Counterfactual analysis") +
  ylab(" Billions (2021 $) ") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() +
  theme(text = element_text(size=17)) +
  # coord_cartesian(ylim = c(0, 80))+  #zoom
  scale_color_manual(values=c('darkmagenta',  'black', 'darkolivegreen4'))
ggsave(width = 11, height = 8, filename = "figures/value-islander-native.jpeg")





#White, asian, black
myTC_race_graph %>%
  filter(race == "Nation" | race == 'White' | race == 'Asian' | race == 'Black') %>%
  ggplot(aes(x = year, y = annual_TC_value_bill, colour = race)) +
  geom_point(size = 2, alpha = .25) +
  geom_smooth(method = "lm", fill = 'grey', size = 1.5) +
  ggtitle("Figure 4: Value estimates are lower for Black and higher for Asian Americans", "Counterfactual analysis") +
  ylab(" Billions (2021 $) ") +
  xlab("Year")+
  labs(caption = "Data Source: ATUS Microdata Activity Summary files, '03-'21")+
  theme_bw() +
  theme(text = element_text(size=17)) +
  # coord_cartesian(ylim = c(0, 80))+  #zoom
  scale_color_manual(values=c('darkcyan', 'darkgoldenrod4', 'black', 'darkred'))
ggsave(width = 11, height = 8, filename = "figures/vale-white-black-asian.jpeg")

```


2003 and 2004 dont have weekly earnings

making the assumption that people who report their weekly earnings are representative of those who dont


# Tables 
```{r, results='asis', echo=FALSE, message=FALSE}
# -----------------------------------------------------------------------------
# Table 1 
# -----------------------------------------------------------------------------

myTable_1 <- myTC %>%
  select(race, year, avg_travel_cost_0, standard_error, annual_TC_value, annual_TC_SE) %>%
  mutate(avg_travel_cost_0 = round(avg_travel_cost_0, 3))%>%
  mutate(standard_error = round(standard_error, 3))%>% 
  mutate(annual_TC_value_bill = round(annual_TC_value / 1e9,3)) %>%
  mutate(annual_TC_SE_bill = round(annual_TC_SE / 1e9, 3)) %>%
  select(race, year, avg_travel_cost_0, standard_error, annual_TC_value_bill, annual_TC_SE_bill) %>%
  select(!race) %>%
  rename(`Daily Value (1 USD)` = avg_travel_cost_0) %>%
  rename(`Std. Err.` = standard_error) %>%
  rename(`Ann. Value (Bill. USD)` = annual_TC_value_bill) %>%
  rename(`Std. Err` = annual_TC_SE_bill)

myTable_1 %>%
  stargazer(title = "Table 2: National Estimates of Daily Recreation Value and Annual Value",
            summary = FALSE, 
            digit.separator= "", 
            out = "figures/tables/National.htm", 
            type = "html")


# -----------------------------------------------------------------------------
# Tables 
# -----------------------------------------------------------------------------

i <- 2
for (r in c("White", "Black", "Native", "Asian", "Islander")) {
  i <- i + 1
  
  temp_table <- myTC_race %>%
    filter(race == r) %>%
    select(!race) %>%
    mutate(avg_travel_cost_0 = round(avg_travel_cost_0, 3))%>%
    mutate(standard_error = round(standard_error, 3))%>% 
    mutate(annual_TC_value_bill = round(annual_TC_value / 1e9,3)) %>%
    mutate(annual_TC_SE_bill = round(annual_TC_SE / 1e9, 3)) %>%
    select(year, avg_travel_cost_0, standard_error, annual_TC_value_bill, annual_TC_SE_bill) %>%
    rename(`Daily Value (1 USD)` = avg_travel_cost_0) %>%
    rename(`Std. Err.` = standard_error) %>%
    rename(`Ann. Value (Bill. USD)` = annual_TC_value_bill) %>%
    rename(`Std. Err` = annual_TC_SE_bill)
  

  
  temp_title <- paste0("Table ", i, ": Daily Value and Counter Factual Annual Value: ", r)
  temp_file_name <- paste0("figures/tables/", r, ".htm")
  
  temp_table %>%
  stargazer(title = temp_title,
            summary = FALSE, 
            digit.separator= "", 
            out = temp_file_name,
            type = "html")

  rm(temp_title, temp_table, temp_file_name)
}
rm(i)

```

# Summary Table

```{r, results='asis', echo=FALSE, message=FALSE}

myValues <- bind_rows(myTC, myTC_race) %>%
  group_by(race) %>%
  mutate(avg_value_annual = round(mean(annual_TC_value)/1e9, 3)) %>%
  mutate(avg_value_daily = round(mean(avg_travel_cost_0),3)) %>%
  select(race, avg_value_daily, avg_value_annual) %>%
  distinct()

myMin_table <- myMinutes_long %>%
  group_by(Race) %>%
  mutate(avg_min = round(mean(avg_min),2)) %>%
  ungroup() %>%
  select(Race, avg_min) %>%
  distinct()

myTable_summary <- left_join(myMin_table, myValues, by = c("Race" = "race")) %>%
    rename(`Daily Value (1 USD)` = avg_value_daily) %>%
    rename(`Ann. Value (Bill. USD)` = avg_value_annual) %>%
    rename(`Avg Min.` = avg_min)


myTable_summary %>%
  stargazer(title = "Table 1: Summary: Averages Across all Years",
            summary = FALSE, 
            digit.separator= "", 
            out = "figures/tables/summary.htm", 
            type = "html")


```





